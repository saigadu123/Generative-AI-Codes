{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k4i_xXGQUv_Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tx5cl7g7bXNx",
    "outputId": "153c4f9b-7e9b-4220-c5ca-5bdaed0cb8fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (0.28.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (0.21.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.10.1)\n",
      "Requirement already satisfied: requests in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2022.9.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.39.2\n",
      "Uninstalling transformers-4.39.2:\n",
      "  Successfully uninstalled transformers-4.39.2\n",
      "Found existing installation: accelerate 0.28.0\n",
      "Uninstalling accelerate-0.28.0:\n",
      "  Successfully uninstalled accelerate-0.28.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.39.2-py3-none-any.whl (8.8 MB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n",
      "Installing collected packages: accelerate, transformers\n",
      "Successfully installed accelerate-0.28.0 transformers-4.39.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe and accelerate.exe are installed in 'C:\\Users\\gorantla.krishna\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\gorantla.krishna\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\gorantla.krishna\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade accelerate\n",
    "#!pip uninstall -y transformers accelerate\n",
    "#!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vj6oYtq8l73x",
    "outputId": "a39d974c-dd47-4de7-e242-1f116dbbd685"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gorantla.krishna\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\gorantla.krishna\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gorantla.krishna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gpGq6rZimhs3"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset,load_from_disk,load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KRCSTxj6cwa8"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_L1yMiP_h0M-"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBvspCLPiOvy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "99dyxoBuk3xb"
   },
   "outputs": [],
   "source": [
    "model = \"google/pegasus-cnn_dailymail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoz0ykJatONs",
    "outputId": "17457b0e-075e-4a2d-a4e5-c2ce392ff0f3"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUgsKKuStZ8w",
    "outputId": "f6ecbbdb-2399-416a-b236-67868e2a0e53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lw34t_4Wtvo5"
   },
   "outputs": [],
   "source": [
    "# Training of the model(Finetuning)\n",
    "# Inferencing (Loading the pretrain model after loading we are just doing the prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UGRUdQIEQQwT"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4L1CYCrJSe7K",
    "outputId": "0ec17a5c-2330-4601-9b7e-6c0f8ae93e7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a41qAyL6SoBa",
    "outputId": "51b58cf1-56d4-4457-fa46-effbc24a33c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amanda: I baked  cookies. Do you want some?\r\n",
      "Jerry: Sure!\r\n",
      "Amanda: I'll bring you tomorrow :-)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][\"dialogue\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nF2fL14TiDf",
    "outputId": "4b0fac9d-1dc6-48e9-c66c-d0f05a746fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amanda baked cookies and will bring Jerry some tomorrow.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][\"summary\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2U67TTiUXGF"
   },
   "source": [
    "### Here I am trying to do summarization of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nyNxb9F5UJym"
   },
   "outputs": [],
   "source": [
    "split_lengths = [len(dataset[split]) for split in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sL_yC2ifWNkl",
    "outputId": "fa7d9775-b1f1-4d19-8f3e-761c9a89badf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14732, 819, 818]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfASPD0kWPY3",
    "outputId": "d4b2f54a-9e67-4830-f7be-1451f1bfa319"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'dialogue', 'summary']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "uF3nX7X4WtHC"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(data_in_batch):\n",
    "\n",
    "    input_encoding = tokenizer(data_in_batch[\"dialogue\"], max_length=1024,truncation=True)\n",
    "\n",
    "    target_encoding = tokenizer(data_in_batch[\"summary\"],max_length=128,truncation=True)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_encoding[\"input_ids\"],\n",
    "        \"attention_mask\": input_encoding[\"attention_mask\"],\n",
    "        \"labels\": target_encoding[\"input_ids\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rpp9tKfNdg2h"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e6fd5a8e0741afaafa1d889bd2375d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_encoded = dataset.map(convert_examples_to_features,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jawReYGadn2s",
    "outputId": "8ac3fe00-901e-46d2-a6a8-017145888fcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13818513',\n",
       " 'dialogue': \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n",
       " 'summary': 'Amanda baked cookies and will bring Jerry some tomorrow.',\n",
       " 'input_ids': [12195,\n",
       "  151,\n",
       "  125,\n",
       "  7091,\n",
       "  3659,\n",
       "  107,\n",
       "  842,\n",
       "  119,\n",
       "  245,\n",
       "  181,\n",
       "  152,\n",
       "  10508,\n",
       "  151,\n",
       "  7435,\n",
       "  147,\n",
       "  12195,\n",
       "  151,\n",
       "  125,\n",
       "  131,\n",
       "  267,\n",
       "  650,\n",
       "  119,\n",
       "  3469,\n",
       "  29344,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [12195, 7091, 3659, 111, 138, 650, 10508, 181, 3469, 107, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QZ704MXoeBnK"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HElncVNUisxY"
   },
   "outputs": [],
   "source": [
    "# FineTuning the model with new data\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"pegasus-samsum\",\n",
    "    num_train_epochs = 1,\n",
    "    warmup_steps = 500,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 1,\n",
    "    weight_decay = 0.01,\n",
    "    logging_steps = 10,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps = 500,\n",
    "    save_steps = 1e6,\n",
    "    gradient_accumulation_steps = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VN7hbjrFnrxw"
   },
   "outputs": [],
   "source": [
    "from  transformers import DataCollatorForSeq2Seq\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer,model=model_pegasus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kfb0OHcRiygG",
    "outputId": "efa62d39-5a9c-4618-96ab-34439b349b09"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model = model_pegasus,\n",
    "                  args = training_args,\n",
    "                  tokenizer=tokenizer,\n",
    "                  data_collator = seq2seq_data_collator,\n",
    "                  train_dataset = dataset_encoded[\"test\"],\n",
    "                  eval_dataset = dataset_encoded[\"validation\"]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "VrDAYObtpCLt",
    "outputId": "00291115-9848-4d69-ae68-c74206945e48"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbMf-A0mptwS"
   },
   "outputs": [],
   "source": [
    "# Evaluation of the model\n",
    "# Evaluation\n",
    "\n",
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n",
    "\n",
    "        # Finally, we decode the generated texts,\n",
    "        # replace the  token, and add the decoded texts with the references to the metric.\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "\n",
    "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "\n",
    "\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    #  Finally compute and return the ROUGE scores.\n",
    "    score = metric.compute()\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_names = [\"rouge1\",\"rouge2\",\"rougeL\",\"rougeLsum\"]\n",
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = calculate_metric_on_test_ds(\n",
    "    dataset['test'][0:10], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",
    ")\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "\n",
    "pd.DataFrame(rouge_dict, index = [f'pegasus'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agTuzEg0scNK"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model_pegasus.save_pretrained(\"pegasus-samsum-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7VB9RDcs3JM"
   },
   "outputs": [],
   "source": [
    "# Save the Tokenizer\n",
    "tokenizer.save_pretrained(\"samsum-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWdSsu-MtuPz"
   },
   "outputs": [],
   "source": [
    "# Load the Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/content/samsum-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-m-wVxDquTbK"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(\"/content/pegasus-samsum-model\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJcslQaMvA1v"
   },
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][\"dialogue\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMZUa8h5v4PO"
   },
   "outputs": [],
   "source": [
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWex-sYtv6Qt"
   },
   "outputs": [],
   "source": [
    "summary_pipeline = pipeline(\"summarization\",model=model_pegasus,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\"length_penalty\":0.8,\"num_beams\":8,\"max_length\":128}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SE9-0M8yx5U9"
   },
   "outputs": [],
   "source": [
    "summary_pipeline(sample_text,**gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnd2XNGyyBsq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
